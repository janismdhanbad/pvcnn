{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare():\n",
    "    from utils.common import get_save_path\n",
    "    from utils.config import configs\n",
    "    from utils.device import set_cuda_visible_devices\n",
    "\n",
    "    # since PyTorch jams device selection, we have to parse args before import torch (issue #26790)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('configs', nargs='+')\n",
    "    parser.add_argument('--devices', default=None)\n",
    "    parser.add_argument('--evaluate', default=False, action='store_true')\n",
    "    args, opts = parser.parse_known_args()\n",
    "    if args.devices is not None and args.devices != 'cpu':\n",
    "        gpus = set_cuda_visible_devices(args.devices)\n",
    "    else:\n",
    "        gpus = []\n",
    "\n",
    "    print(f'==> loading configs from {args.configs}')\n",
    "    configs.update_from_modules(*args.configs)\n",
    "    # define save path\n",
    "    configs.train.save_path = get_save_path(*args.configs, prefix='runs')\n",
    "\n",
    "    # override configs with args\n",
    "    configs.update_from_arguments(*opts)\n",
    "    if len(gpus) == 0:\n",
    "        configs.device = 'cpu'\n",
    "        configs.device_ids = []\n",
    "    else:\n",
    "        configs.device = 'cuda'\n",
    "        configs.device_ids = gpus\n",
    "    if args.evaluate and configs.evaluate.fn is not None:\n",
    "        if 'dataset' in configs.evaluate:\n",
    "            for k, v in configs.evaluate.dataset.items():\n",
    "                configs.dataset[k] = v\n",
    "    else:\n",
    "        configs.evaluate = None\n",
    "\n",
    "    if configs.evaluate is None:\n",
    "        metrics = []\n",
    "        if 'metric' in configs.train and configs.train.metric is not None:\n",
    "            metrics.append(configs.train.metric)\n",
    "        if 'metrics' in configs.train and configs.train.metrics is not None:\n",
    "            for m in configs.train.metrics:\n",
    "                if m not in metrics:\n",
    "                    metrics.append(m)\n",
    "        configs.train.metrics = metrics\n",
    "        configs.train.metric = None if len(metrics) == 0 else metrics[0]\n",
    "\n",
    "        save_path = configs.train.save_path\n",
    "        configs.train.checkpoint_path = os.path.join(save_path, 'latest.pth.tar')\n",
    "        configs.train.checkpoints_path = os.path.join(save_path, 'latest', 'e{}.pth.tar')\n",
    "        configs.train.best_checkpoint_path = os.path.join(configs.train.save_path, 'best.pth.tar')\n",
    "        best_checkpoints_dir = os.path.join(save_path, 'best')\n",
    "        configs.train.best_checkpoint_paths = {\n",
    "            m: os.path.join(best_checkpoints_dir, 'best.{}.pth.tar'.format(m.replace('/', '.')))\n",
    "            for m in configs.train.metrics\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(configs.train.checkpoints_path), exist_ok=True)\n",
    "        os.makedirs(best_checkpoints_dir, exist_ok=True)\n",
    "    else:\n",
    "        if 'best_checkpoint_path' not in configs.evaluate or configs.evaluate.best_checkpoint_path is None:\n",
    "            if 'best_checkpoint_path' in configs.train and configs.train.best_checkpoint_path is not None:\n",
    "                configs.evaluate.best_checkpoint_path = configs.train.best_checkpoint_path\n",
    "            else:\n",
    "                configs.evaluate.best_checkpoint_path = os.path.join(configs.train.save_path, 'best.pth.tar')\n",
    "        assert configs.evaluate.best_checkpoint_path.endswith('.pth.tar')\n",
    "        configs.evaluate.predictions_path = configs.evaluate.best_checkpoint_path.replace('.pth.tar', '.predictions')\n",
    "        configs.evaluate.stats_path = configs.evaluate.best_checkpoint_path.replace('.pth.tar', '.eval.npy')\n",
    "\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> loading configs from ['C:\\\\Users\\\\SING1761\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-485bb8ab-49f2-42e3-a955-477536ef7d36.json']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'C:\\\\Users\\\\SING1761\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-485bb8ab-49f2-42e3-a955-477536ef7d36'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-43571dfa7d22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfigs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7a5efdfd28bb>\u001b[0m in \u001b[0;36mprepare\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'==> loading configs from {args.configs}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_from_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m# define save path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_save_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive Corp\\OneDrive - Atkins Ltd\\my_work\\3D_data\\pvcnn\\pvcnn\\utils\\config.py\u001b[0m in \u001b[0;36mupdate_from_modules\u001b[1;34m(*modules)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.py'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'C:\\\\Users\\\\SING1761\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-485bb8ab-49f2-42e3-a955-477536ef7d36'"
     ]
    }
   ],
   "source": [
    "configs = prepare()\n",
    "if configs.evaluate is not None:\n",
    "    configs.evaluate.fn(configs)\n",
    "    return\n",
    "\n",
    "import numpy as np\n",
    "import tensorboardX\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    configs = prepare()\n",
    "    if configs.evaluate is not None:\n",
    "        configs.evaluate.fn(configs)\n",
    "        return\n",
    "\n",
    "    import numpy as np\n",
    "    import tensorboardX\n",
    "    import torch\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    from torch.utils.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ################################\n",
    "    # Train / Eval Kernel Function #\n",
    "    ################################\n",
    "\n",
    "    # train kernel\n",
    "    def train(model, loader, criterion, optimizer, scheduler, current_step, writer):\n",
    "        model.train()\n",
    "        for inputs, targets in tqdm(loader, desc='train', ncols=0):\n",
    "            if isinstance(inputs, dict):\n",
    "                for k, v in inputs.items():\n",
    "                    batch_size = v.size(0)\n",
    "                    inputs[k] = v.to(configs.device, non_blocking=True)\n",
    "            else:\n",
    "                batch_size = inputs.size(0)\n",
    "                inputs = inputs.to(configs.device, non_blocking=True)\n",
    "            if isinstance(targets, dict):\n",
    "                for k, v in targets.items():\n",
    "                    targets[k] = v.to(configs.device, non_blocking=True)\n",
    "            else:\n",
    "                targets = targets.to(configs.device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            writer.add_scalar('loss/train', loss.item(), current_step)\n",
    "            current_step += batch_size\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    # evaluate kernel\n",
    "    def evaluate(model, loader, split='test'):\n",
    "        meters = {}\n",
    "        for k, meter in configs.train.meters.items():\n",
    "            meters[k.format(split)] = meter()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(loader, desc=split, ncols=0):\n",
    "                if isinstance(inputs, dict):\n",
    "                    for k, v in inputs.items():\n",
    "                        inputs[k] = v.to(configs.device, non_blocking=True)\n",
    "                else:\n",
    "                    inputs = inputs.to(configs.device, non_blocking=True)\n",
    "                if isinstance(targets, dict):\n",
    "                    for k, v in targets.items():\n",
    "                        targets[k] = v.to(configs.device, non_blocking=True)\n",
    "                else:\n",
    "                    targets = targets.to(configs.device, non_blocking=True)\n",
    "                outputs = model(inputs)\n",
    "                for meter in meters.values():\n",
    "                    meter.update(outputs, targets)\n",
    "        for k, meter in meters.items():\n",
    "            meters[k] = meter.compute()\n",
    "        return meters\n",
    "\n",
    "    ###########\n",
    "    # Prepare #\n",
    "    ###########\n",
    "\n",
    "    if configs.device == 'cuda':\n",
    "        cudnn.benchmark = True\n",
    "        if configs.get('deterministic', False):\n",
    "            cudnn.deterministic = True\n",
    "            cudnn.benchmark = False\n",
    "    if ('seed' not in configs) or (configs.seed is None):\n",
    "        configs.seed = torch.initial_seed() % (2 ** 32 - 1)\n",
    "    seed = configs.seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    print(configs)\n",
    "\n",
    "    #####################################################################\n",
    "    # Initialize DataLoaders, Model, Criterion, LRScheduler & Optimizer #\n",
    "    #####################################################################\n",
    "\n",
    "    print(f'\\n==> loading dataset \"{configs.dataset}\"')\n",
    "    dataset = configs.dataset()\n",
    "    loaders = {}\n",
    "    for split in dataset:\n",
    "        loaders[split] = DataLoader(\n",
    "            dataset[split], shuffle=(split == 'train'), batch_size=configs.train.batch_size,\n",
    "            num_workers=configs.data.num_workers, pin_memory=True,\n",
    "            worker_init_fn=lambda worker_id: np.random.seed(seed + worker_id)\n",
    "        )\n",
    "\n",
    "    print(f'\\n==> creating model \"{configs.model}\"')\n",
    "    model = configs.model()\n",
    "    if configs.device == 'cuda':\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model = model.to(configs.device)\n",
    "    criterion = configs.train.criterion().to(configs.device)\n",
    "    optimizer = configs.train.optimizer(model.parameters())\n",
    "\n",
    "    last_epoch, best_metrics = -1, {m: None for m in configs.train.metrics}\n",
    "    if os.path.exists(configs.train.checkpoint_path):\n",
    "        print(f'==> loading checkpoint \"{configs.train.checkpoint_path}\"')\n",
    "        checkpoint = torch.load(configs.train.checkpoint_path)\n",
    "        print(' => loading model')\n",
    "        model.load_state_dict(checkpoint.pop('model'))\n",
    "        if 'optimizer' in checkpoint and checkpoint['optimizer'] is not None:\n",
    "            print(' => loading optimizer')\n",
    "            optimizer.load_state_dict(checkpoint.pop('optimizer'))\n",
    "        last_epoch = checkpoint.get('epoch', last_epoch)\n",
    "        meters = checkpoint.get('meters', {})\n",
    "        for m in configs.train.metrics:\n",
    "            best_metrics[m] = meters.get(m + '_best', best_metrics[m])\n",
    "        del checkpoint\n",
    "\n",
    "    if 'scheduler' in configs.train and configs.train.scheduler is not None:\n",
    "        configs.train.scheduler.last_epoch = last_epoch\n",
    "        print(f'==> creating scheduler \"{configs.train.scheduler}\"')\n",
    "        scheduler = configs.train.scheduler(optimizer)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    ############\n",
    "    # Training #\n",
    "    ############\n",
    "\n",
    "    if last_epoch >= configs.train.num_epochs:\n",
    "        meters = dict()\n",
    "        for split, loader in loaders.items():\n",
    "            if split != 'train':\n",
    "                meters.update(evaluate(model, loader=loader, split=split))\n",
    "        for k, meter in meters.items():\n",
    "            print(f'[{k}] = {meter:2f}')\n",
    "        return\n",
    "\n",
    "    with tensorboardX.SummaryWriter(configs.train.save_path) as writer:\n",
    "        for current_epoch in range(last_epoch + 1, configs.train.num_epochs):\n",
    "            current_step = current_epoch * len(dataset['train'])\n",
    "\n",
    "            # train\n",
    "            print(f'\\n==> training epoch {current_epoch}/{configs.train.num_epochs}')\n",
    "            train(model, loader=loaders['train'], criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n",
    "                  current_step=current_step, writer=writer)\n",
    "            current_step += len(dataset['train'])\n",
    "\n",
    "            # evaluate\n",
    "            meters = dict()\n",
    "            for split, loader in loaders.items():\n",
    "                if split != 'train':\n",
    "                    meters.update(evaluate(model, loader=loader, split=split))\n",
    "\n",
    "            # check whether it is the best\n",
    "            best = {m: False for m in configs.train.metrics}\n",
    "            for m in configs.train.metrics:\n",
    "                if best_metrics[m] is None or best_metrics[m] < meters[m]:\n",
    "                    best_metrics[m], best[m] = meters[m], True\n",
    "                meters[m + '_best'] = best_metrics[m]\n",
    "            # log in tensorboard\n",
    "            for k, meter in meters.items():\n",
    "                print(f'[{k}] = {meter:2f}')\n",
    "                writer.add_scalar(k, meter, current_step)\n",
    "\n",
    "            # save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': current_epoch,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'meters': meters,\n",
    "                'configs': configs,\n",
    "            }, configs.train.checkpoint_path)\n",
    "            shutil.copyfile(configs.train.checkpoint_path, configs.train.checkpoints_path.format(current_epoch))\n",
    "            for m in configs.train.metrics:\n",
    "                if best[m]:\n",
    "                    shutil.copyfile(configs.train.checkpoint_path, configs.train.best_checkpoint_paths[m])\n",
    "            if best.get(configs.train.metric, False):\n",
    "                shutil.copyfile(configs.train.checkpoint_path, configs.train.best_checkpoint_path)\n",
    "            print(f'[save_path] = {configs.train.save_path}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
